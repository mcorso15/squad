{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9a9bb0c-0fd5-4f89-a749-cd8a85d21c61",
   "metadata": {},
   "source": [
    "# GPGN268 - Geophysical Data Analysis\n",
    "## Data Story 03 - Seismology\n",
    "\n",
    "**Student:** Lexi Herr\n",
    "**Collaborators:** Jackson Kreiger, Mia Jungman\n",
    "**Date:** April 6, 2023\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a73ec4f-a1f4-427f-a3ee-6a4ff19fef1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b87a3fb-2a1b-42af-a66d-a58ed382dc88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "files_list = sorted(glob.glob('../data/DAS/Global_DAS_1078DT_25PR_14GL_5DEC_2023-02*.h5'))\n",
    "data = h5py.File(files_list[0], 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c9676a-2d03-4b88-93d4-80a81d285e58",
   "metadata": {},
   "source": [
    "## Task 1 - Reading the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59bb6dc6-d9eb-42fd-a895-fdd911375750",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def strain_and_timing(path):\n",
    "    \"\"\"Return strain and timing\n",
    "    Args: path(str): path to a given DAS .h5 file\n",
    "    Returns: returns the strain and timing data in the file\"\"\"\n",
    "    with h5py.File(path) as data:\n",
    "        strain = data['Acquisition']['Raw[0]']['RawData'][:]\n",
    "        time = data['Acquisition']['Raw[0]']['RawDataTime'][:]\n",
    "    return strain, time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4482eb0-2154-4d49-a2d4-6e8d3da77e30",
   "metadata": {},
   "source": [
    "## Task 2 - Time and time again\n",
    "### Task 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7eb70e96-1c71-4a4b-9809-d48a3f7e8b77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_time(path):\n",
    "    with h5py.File(path) as data:\n",
    "        time_string = os.path.basename(data.filename).split('_')[-1].split('.')[0][:-1]\n",
    "    return time_string\n",
    "\n",
    "ts = find_time('../data/DAS/Global_DAS_1078DT_25PR_14GL_5DEC_2023-02-17T164133Z.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5391d908-6471-436f-9fc3-b61d08427700",
   "metadata": {},
   "source": [
    "### Task 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc3644bc-88e4-4e4e-a1a7-e4f57b204d5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "time_stamp = pd.to_datetime(ts, format='%Y-%m-%dT%H%M%S', utc=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeddba49-81c5-4600-aadb-21ff9c8e14ca",
   "metadata": {},
   "source": [
    "### Task 2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1abfa236-edf9-4983-ae80-5f0186902ee4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_measurements = data['Acquisition']['Raw[0]']['RawDataTime'][:]\n",
    "total_time = len(total_measurements) / 500\n",
    "interval = 1/500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa38387-0c7a-4b53-b930-cde5e33f6f07",
   "metadata": {},
   "source": [
    "### Task 2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f8e080-c7b0-4ba3-8608-ef5f3364125c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "end_time = time_stamp + pd.Timedelta(60, 's')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4149fcc-66ee-4eee-a46e-abf1b130b99a",
   "metadata": {},
   "source": [
    "### Task 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fa20a0-46dc-4029-82bd-e457b52a4dc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "time_utc = pd.date_range(start=time_stamp, end=end_time, periods=len(total_measurements))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d69c5fc-adb7-4cb4-a5ad-37eb9715ebb3",
   "metadata": {},
   "source": [
    "### Task 2.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ea7724-3fd7-4f8b-bd06-774889f520f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "time = time_utc.tz_convert('US/Mountain')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12822aa4-8601-4666-ae31-bb8897e2edec",
   "metadata": {},
   "source": [
    "### Task 2.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39725061-2a3c-4975-9290-cd43c36c3118",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data_to_mountain_time(path):\n",
    "    \"\"\"Return time values converted to mountain time\n",
    "    Args: path(str): path to a given DAS .h5 file\n",
    "    Returns: MST of time data in the file\"\"\"\n",
    "    with h5py.File(path) as data:\n",
    "        time_string = os.path.basename(data.filename).split('_')[-1].split('.')[0][:-1]\n",
    "        ts = find_time(path)\n",
    "        time_stamp = pd.to_datetime(ts, format='%Y-%m-%dT%H%M%S', utc=True)\n",
    "        total_measurements = data['Acquisition']['Raw[0]']['RawDataTime'][:]\n",
    "        end_time = time_stamp + pd.Timedelta(60, 's')\n",
    "        time_utc = pd.date_range(start=time_stamp, end=end_time, periods=len(total_measurements))\n",
    "        time = time_utc.tz_convert('US/Mountain')\n",
    "    return time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64d17a8-ddc2-4cb4-a42d-d01d1dcf0026",
   "metadata": {},
   "source": [
    "## Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5dbc43-97d6-40d3-840e-3e3760eb5bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strain_rate(path):\n",
    "    with h5py.File(path) as data:\n",
    "        strain, time = strain_and_timing(path)\n",
    "        strain_diff = np.diff(strain, axis=0)\n",
    "        dt = (time[1]-time[0]).total_seconds()\n",
    "        sr = strain_diff/dt\n",
    "        time = time[:-1]\n",
    "    return sr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5f2fe7-3073-4cd4-ab9a-39155339dde5",
   "metadata": {},
   "source": [
    "## Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0188db18-0262-4aab-af7a-ede8ac18758c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def strain_rate_and_mountain_time(path):\n",
    "    \"\"\"Return strain rate and mountain time\n",
    "    Args: path(str): path to a given DAS .h5 file\n",
    "    Returns: returns the strain rate and MST of time data in file\"\"\"\n",
    "    mountain_time = data_to_mountain_time(path)\n",
    "    strain, time = strain_and_timing(path)\n",
    "    strain_diff = np.diff(strain,axis=0)\n",
    "    mountain_time = mountain_time[:-1]\n",
    "    dt = (mountain_time[1]-mountain_time[0]).total_seconds()\n",
    "    strain_rate = strain_diff/dt\n",
    "    return strain_rate, mountain_time "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
